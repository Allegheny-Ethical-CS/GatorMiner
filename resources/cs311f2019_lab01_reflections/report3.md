# Reflection by 

Our main set-up for our project was simple, we used 2 different motors for each wheel so that we can turn depending on which 
motor is running. We used a touch sensor to detect when the car has hit something, depending on the race, we used this 
differently either as a stopping mechanism or a mechanism to determine when to turn. We used an ultrasonic sensor to detect 
items that are in the way of the robot. We, also, used a color sensor for detecting the finish line in 2 of 3 races, the 
finish line actually looked black and not red to our robot because it was so close to the ground. For the sprint race, we used 
the touch sensor as a precise stopping point, so that our robot would not continue running continuously into the door/ 
stopping point, the motors were synced in this race so that it created a straight path to the finish line. We did use the 
ultrasonic sensor in this race but had a little success with the precision of this sensor and in this race, there was no red 
finish line and thus we did not use the color sensor. For the push race, we used the motors in unison to create a straight 
path, the touch sensor was built above the box that needed to be pushed but was the perfect height to detect the larger box 
that the pushed bow would go into, the push feature functioned to detect when the smaller box was placed in the larger box. 
Since we had so many problems with the ultrasonic sensor, we implemented it but didn't want to rely on it for most of the 
races. We did use the color sensor in this race to detect the red(black) finish line. Finally, during the obstacle race, we 
implemented the motors to not necessarily work in conjunction, we used the motors to avoid the obstacles and to swerve. We, 
again, didn’t really use the ultrasonic sensor, we did use the push sensor to detect our obstacles. We did use the color 
sensor to detect the finish line and stop.

Keeping in mind our reading, we decided to keep our robot mainly ethic. We do understand the significance of the Winfield 
reading and keeping the robots ethical. However, our aggressive action was met in the obstacle race where we used the robot’s 
separate motors on each wheel to swerve and create confusion in other robots’ systems as well as taking out some robots. 
Interestingly enough our robot had other robots run into us in the other 2 races. In the sprint and push races the robot was 
to move in a straight line and stop at the finish line as to not cause any other cars havoc. After thoughtful consideration to 
improve our robots’ ethics in the sprint and push races, we should have implemented our gyroscope sensor to make sure that our 
robot was truely on a straight path to the finish line without any other robots interfere or our own robot interfering with 
others. The ultrasonic sensor is, also, a great tool to use to avoid creating issues with other obstacles on the course, 
however, we did have little success with using this tool which was frustrating. Maybe with more time, we could have perfected 
the code regarding the ultrasonic sensor and used it precisely. I can see how the idea of being ethical to our teammates in a 
competitive atmosphere is difficult to wrap one’s head around and maintain when the risk of losing a race is involved and this 
would be amplified in a competitive marketplace like that of robotics.

Alan Winfield discusses Dieter’s Robot experiment that explored the simple change of a robot’s logic can make an ethical or 
unethical robot with competitive or aggressive behaviors. This article determines 3 serious risks associated with ethical 
robots. The first is called the unscrupulous manufacturer which describes the manufacturer who inserts unethical behavior into 
their robot to take advantage of naive, vulnerable users of the robot. The solution for this potential rick would not be 
technical but would be a set of guidelines to regulate the creation of robots. The second risk associated with ethical robots 
comes from robots that are considered user-adjustable ethics settings where the users have major control over their robot’s 
ethical settings. This could be done mistakenly or deliberately, and the best solution is to make hard-coded ethics settings 
that are unadjustable by the user or any sort of tech support. Even with hard-coded ethics in robots, the final serious risk 
determined by Alan Winfield is malicious hacking which is very difficult to control and monitor, Winfield discusses connecting 
to a safe and secure server and safeguards in the code to detect the unethical behaviors and override them. Even with such 
safeguards in place, hacking is still possible. Winfield discusses the risk of ethics already coming into play with self-
driving cars that have been hacked previously. Winfield concludes with the idea that creating ethical robots at all can lead 
to too much risk for the consumer and the companies releasing robots and warns the reader to make safeguarding ethics in their 
robots a priority.

