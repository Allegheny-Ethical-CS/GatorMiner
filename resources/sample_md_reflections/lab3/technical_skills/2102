## Text Generation

For the text generation I used GPT-2-simple and Google Colab. I followed the guides in the
notebook([link](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#forceEdit=true&sandboxMode=true&scrollTo=sUmTooTW3osf)). First I created my copy in the
drive. Then I uploaded the file `sample.txt` to my Google drive. I updated the
file name in the code in my copy of the notebook.
And then ran the code for finetuning. What this
code does is that it loads the data set and trains for certain number of steps,
that is one of the parameters and can be modified, but I kept the default.
When finetuning I coould also see the output. According to Max Woolf ([link](https://minimaxir.com/2019/09/howto-gpt2/))
In the output if the average loss stops decreasing it means that additional
training may not improve the model. I observed that the average loss in my output
kept decreasing until reaching 0.01. After the model finished training I ran
the cell for saving it to the drive. Then I downloaded that drive locally and
then followed the steps in the `README.md` for text generation([link](https://github.com/minimaxir/gpt-2-simple)). Since my model
was already trained, all I had to do was to load it from the file `/checkpoint/run1`,
that's where the generated model goes by default. Then I called the `generate`
function. I passed in parameters for
`length`, `temperature`, `top_k`, `top_p`, `prefix`. The `temperature` was
recommended to be between 0.7 and 1.0. So I changed it multiple times and
observed the output and finally kept 1.0. For `top_k` I set 40, which would
limit the generated guesses to top 40 guesses. The output of the `generator`
is below. If one runs `generator` again content might be different.

```
Future of technology. Its a brave choice. Im sorry, but I... I couldnt do it.
OK, I was going to play some redos from the Fraser O days. Stuff from last
night, depressing and fun. You know half the organic memories you have a
junk, just not trustworthy. Colleen works in Grain development. With half
the population you can implant false memories, just by asking leading
questions in therapy. You can make people remember getting lost in shopping
malls they never visited, getting bothered by

```

